# FinRAG - Financial Retrieval-Augmented Generation# FinRAG - Financial Retrieval-Augmented Generation# FinRAG: Financial Retrieval-Augmented Generation



[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A powerful Financial RAG system based on the RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) architecture, optimized for financial documents and analysis.A sophisticated implementation of Retrieval-Augmented Generation (RAG) for financial documents, built on top of RAPTOR's hierarchical tree structure for improved context retrieval and question answering.

A sophisticated implementation of Retrieval-Augmented Generation (RAG) for financial documents, built on RAPTOR's hierarchical tree structure for improved context retrieval and question answering.



## ğŸŒŸ Overview

## ğŸ“ Project Structure## Overview

FinRAG combines the power of RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) with financial domain-specific optimizations to create a state-of-the-art system for querying financial documents.



### Key Features

```FinRAG combines the power of RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) with financial domain-specific optimizations to create a state-of-the-art system for querying financial documents.

- ğŸŒ³ **Hierarchical Tree Structure** - Multi-level document representation using RAPTOR

- ğŸ“Š **Financial Context Awareness** - Specialized processing for financial documentsFinRAG/

- ğŸ“„ **Advanced PDF Parsing** - LlamaParse integration with PyPDF2 fallback

- ğŸ” **Multiple Retrieval Strategies** - Tree traversal and collapsed tree searchâ”œâ”€â”€ src/finrag/              # Source code (organized by functionality)### Key Features

- ğŸ¯ **Semantic Search** - Powered by OpenAI embeddings

- âš¡ **Caching Support** - Save and load processed indicesâ”œâ”€â”€ examples/                # Ready-to-run examples

- ğŸ”§ **Extensible Architecture** - Easy to customize and extend

â”œâ”€â”€ tests/                   # Testing scripts- **Hierarchical Tree Structure**: Uses RAPTOR's recursive clustering to build multi-level document representations

## ğŸ“ Project Structure

â”œâ”€â”€ docs/                    # Comprehensive documentation- **Advanced PDF Parsing**: Integrated LlamaParse for superior table/layout extraction (with PyPDF2 fallback)

```

FinRAG/â”œâ”€â”€ scripts/                 # Utility scripts- **Financial Context Awareness**: Specialized chunking and summarization for financial documents

â”œâ”€â”€ src/finrag/              # Source code

â”‚   â”œâ”€â”€ core/               # Core algorithmsâ”œâ”€â”€ data/                    # Data files and samples- **Multiple Retrieval Strategies**: 

â”‚   â”œâ”€â”€ models/             # Model implementations

â”‚   â””â”€â”€ utils/              # Utilitiesâ””â”€â”€ requirements.txt         # Python dependencies  - Tree Traversal: Navigate from high-level summaries to detailed information

â”œâ”€â”€ examples/               # Usage examples

â”œâ”€â”€ tests/                  # Testing scripts```  - Collapsed Tree: Search across all abstraction levels simultaneously

â”œâ”€â”€ docs/                   # Documentation

â””â”€â”€ requirements.txt        # Dependencies- **Semantic Search**: Leverages OpenAI embeddings for accurate document retrieval

```

See [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) for detailed organization.- **Extensible Architecture**: Easy to swap models (embeddings, LLMs, summarization)

See [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) for detailed organization.



## ğŸš€ Quick Start

## ğŸš€ Quick Start## Architecture

### 1. Install Dependencies



```bash

pip install -r requirements.txt### 1. Install Dependencies```

```

FinRAG Architecture:

Or install as a package:

```powershellâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```bash

pip install -e .pip install -r requirements.txtâ”‚                    Financial Documents                       â”‚

```

```â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 2. Configure API Keys

                        â”‚

Create a `.env` file from the template:

Or install as a package:                        â–¼

```bash

cp .env.example .envâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```

```powershellâ”‚                  Document Chunking                           â”‚

Add your API keys:

pip install -e .â”‚              (Financial-aware chunking)                      â”‚

```bash

OPENAI_API_KEY=sk-your-key-here```â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LLAMA_CLOUD_API_KEY=llx-your-key-here  # Optional but recommended

```                        â”‚



### 3. Run Examples### 2. Configure API Keys                        â–¼



```bashâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# Simple example with sample data

python examples/example.py```powershellâ”‚                  Embedding Generation                        â”‚



# Full PDF example# Copy the templateâ”‚              (OpenAI text-embedding-3-small)                 â”‚

python examples/main.py

Copy-Item .env.example .envâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Interactive CLI

python examples/cli.py                        â”‚

```

# Edit .env and add your keys                        â–¼

## ğŸ’» Usage

notepad .envâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

### Basic Usage

```â”‚                   RAPTOR Tree Building                       â”‚

```python

from finrag import FinRAG, FinRAGConfigâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚



# Initialize (automatically loads from .env)Add your API keys to `.env`:â”‚  â”‚         Level 2: High-level summaries               â”‚   â”‚

config = FinRAGConfig()

finrag = FinRAG(config)```bashâ”‚  â”‚                     /  |  \                          â”‚   â”‚



# Add documentsOPENAI_API_KEY=sk-your-key-hereâ”‚  â”‚         Level 1: Mid-level summaries                â”‚   â”‚

documents = ["Your financial text here..."]

finrag.add_documents(documents)LLAMA_CLOUD_API_KEY=llx-your-key-here  # Optional but recommendedâ”‚  â”‚                 /   |   |   \                        â”‚   â”‚



# Query```â”‚  â”‚         Level 0: Original chunks                    â”‚   â”‚

result = finrag.query("What is the revenue trend?")

print(result['answer'])â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚

```

### 3. Run Examplesâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### With PDF

                        â”‚

```python

# Load PDF```powershell                        â–¼

finrag.load_pdf("financial_report.pdf")

# Simple example with sample dataâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# Query

result = finrag.query("What are the key financial metrics?")python examples/example.pyâ”‚              Query Processing & Retrieval                    â”‚

print(result['answer'])

```â”‚  â€¢ Tree Traversal: Top-down navigation                      â”‚



### Custom Configuration# Full PDF exampleâ”‚  â€¢ Collapsed Tree: Cross-level search                       â”‚



```pythonpython examples/main.pyâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

config = FinRAGConfig(

    chunk_size=1024,                        â”‚

    top_k=20,

    tree_depth=4,# Interactive CLI                        â–¼

    summarization_model="gpt-4-turbo-preview"

)python examples/cli.pyâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

finrag = FinRAG(config)

``````â”‚                Question Answering                            â”‚



## ğŸ—ï¸ Architectureâ”‚              (GPT-4 with retrieved context)                  â”‚



```## ğŸ“š Documentationâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚     Financial Documents             â”‚```

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”‚Comprehensive documentation is available in the [`docs/`](docs/) folder:

              â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”## Installation

â”‚     Document Chunking               â”‚

â”‚  (Financial-aware chunking)         â”‚- **[README.md](docs/README.md)** - Complete system documentation

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”‚- **[GETTING_STARTED.md](docs/GETTING_STARTED.md)** - Quick start guide### Prerequisites

              â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- **[IMPLEMENTATION.md](docs/IMPLEMENTATION.md)** - Technical implementation details

â”‚     Embedding Generation            â”‚

â”‚  (OpenAI text-embedding-3-small)    â”‚- **[SETUP.md](docs/SETUP.md)** - Detailed setup instructions- Python 3.8 or higher

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”‚- **[ENV_SETUP.md](docs/ENV_SETUP.md)** - Environment variables guide- OpenAI API key

              â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- **[QUICKREF.md](docs/QUICKREF.md)** - Quick reference guide

â”‚     RAPTOR Tree Building            â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚- **[LLAMAPARSE.md](docs/LLAMAPARSE.md)** - LlamaParse integration guide### Setup

â”‚  â”‚  Level 2: High-level        â”‚   â”‚

â”‚  â”‚  Level 1: Mid-level         â”‚   â”‚

â”‚  â”‚  Level 0: Original chunks   â”‚   â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚## ğŸ—ï¸ Architecture1. Clone or download this repository:

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”‚```bash

              â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”FinRAG uses a hierarchical tree structure (RAPTOR) to organize and retrieve information:cd FinRAG

â”‚  Query Processing & Retrieval       â”‚

â”‚  â€¢ Tree Traversal                   â”‚```

â”‚  â€¢ Collapsed Tree Search            â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

              â”‚

              â–¼Level 2: High-level summaries (Root)2. Install dependencies:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚     Question Answering              â”‚         â†“```bash

â”‚  (GPT-4 with context)               â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Level 1: Mid-level summaries (Clusters)pip install -r requirements.txt

```

         â†“```

### Core Components

Level 0: Original chunks (Leaves)

- **Core** (`src/finrag/core/`)

  - `base_models.py` - Abstract base classes```3. Set your OpenAI API key:

  - `clustering.py` - RAPTOR clustering algorithm

  - `tree.py` - Hierarchical tree structure

  - `retrieval.py` - Tree traversal and retrieval

### Key Components**Option 1: Environment Variable**

- **Models** (`src/finrag/models/`)

  - `models.py` - OpenAI implementations```bash



- **Utils** (`src/finrag/utils/`)- **Core** (`src/finrag/core/`)# Windows PowerShell

  - `env_loader.py` - Environment variable management

  - `utils.py` - General utilities  - `base_models.py` - Abstract base classes$env:OPENAI_API_KEY="your-api-key-here"



## ğŸ”§ Configuration  - `clustering.py` - RAPTOR clustering algorithm$env:LLAMA_CLOUD_API_KEY="your-llama-key-here"  # Optional but recommended



Configure via `.env` file or environment variables:  - `tree.py` - Hierarchical tree structure



```bash  - `retrieval.py` - Tree traversal and retrieval# Linux/Mac

# Required

OPENAI_API_KEY=sk-...export OPENAI_API_KEY="your-api-key-here"



# Recommended- **Models** (`src/finrag/models/`)export LLAMA_CLOUD_API_KEY="your-llama-key-here"  # Optional but recommended

LLAMA_CLOUD_API_KEY=llx-...

  - `models.py` - OpenAI implementations (embeddings, QA, summarization)```

# Optional customization

FINRAG_CHUNK_SIZE=512

FINRAG_TOP_K=10

FINRAG_TREE_DEPTH=3- **Utils** (`src/finrag/utils/`)**Option 2: In Code**

FINRAG_SUMMARIZATION_MODEL=gpt-3.5-turbo

FINRAG_EMBEDDING_MODEL=text-embedding-3-small  - `env_loader.py` - Environment variable management```python

FINRAG_LLM_MODEL=gpt-4-turbo-preview

```  - `utils.py` - General utilitiesfrom config import FinRAGConfig



See [docs/ENV_SETUP.md](docs/ENV_SETUP.md) for all available options.



## ğŸ“š Documentation## ğŸ’» Usage Examplesconfig = FinRAGConfig(



Comprehensive documentation available in [`docs/`](docs/):    openai_api_key="your-api-key-here",



- **[README.md](docs/README.md)** - Complete documentation### Basic Usage    llamaparse_api_key="your-llama-key-here"  # Optional but recommended

- **[GETTING_STARTED.md](docs/GETTING_STARTED.md)** - Quick start guide

- **[IMPLEMENTATION.md](docs/IMPLEMENTATION.md)** - Technical details)

- **[ENV_SETUP.md](docs/ENV_SETUP.md)** - Configuration guide

- **[QUICKREF.md](docs/QUICKREF.md)** - Quick reference```python```

- **[LLAMAPARSE.md](docs/LLAMAPARSE.md)** - PDF parsing guide

from finrag import FinRAG, FinRAGConfig

## ğŸ§ª Testing

**Note**: LlamaParse API key is optional but **highly recommended** for financial documents with tables and complex layouts. See [LLAMAPARSE.md](LLAMAPARSE.md) for details.

```bash

# Test installation# Initialize (automatically loads from .env)

python tests/test_installation.py

config = FinRAGConfig()## Quick Start

# Test API keys

python tests/test_openai_key.pyfinrag = FinRAG(config)

```

### Basic Usage

## ğŸ“¦ Package Installation

# Add documents

Install as a package for use in other projects:

documents = ["Your financial text here..."]```python

```bash

# Development mode (editable)finrag.add_documents(documents)import os

pip install -e .

from config import FinRAGConfig

# Production mode

pip install .# Queryfrom finrag import FinRAG

```

result = finrag.query("What is the revenue trend?")

Then import anywhere:

print(result['answer'])# Initialize FinRAG

```python

from finrag import FinRAG, FinRAGConfig```config = FinRAGConfig(

```

    openai_api_key=os.getenv("OPENAI_API_KEY"),

## ğŸ¯ Advanced Features

### With PDF    chunk_size=512,

### Saving and Loading

    top_k=10,

```python

# Save processed index```python    tree_depth=3

finrag.save("./my_index")

# Load PDF)

# Load later

finrag_new = FinRAG(config)finrag.load_pdf("path/to/financial_report.pdf")

finrag_new.load("./my_index")

```finrag = FinRAG(config)



### Custom Retrieval# Query



```pythonresult = finrag.query("What are the key financial metrics?")# Load a financial document

# Tree traversal (default)

result = finrag.query(```text = finrag.load_pdf("financial_report.pdf")

    "Give me an overview",

    retrieval_method="tree_traversal"

)

### Custom Configuration# Build the RAPTOR tree

# Collapsed tree (for specific queries)

result = finrag.query(finrag.add_documents([text])

    "What was the exact revenue?",

    retrieval_method="collapsed_tree"```python

)

```config = FinRAGConfig(# Query the system



### Access Retrieved Context    chunk_size=1024,result = finrag.query("What is the revenue growth rate?")



```python    top_k=20,print(result['answer'])

result = finrag.query("What are the risk factors?")

print(f"Answer: {result['answer']}")    tree_depth=4,```

print(f"\nRetrieved {len(result['retrieved_nodes'])} nodes:")

    summarization_model="gpt-4-turbo-preview"

for node in result['retrieved_nodes'][:5]:

    print(f"- Level {node['level']} (Score: {node['score']:.3f})"))### Running the Demo

```

finrag = FinRAG(config)

## ğŸ” How It Works

``````bash

### 1. Document Processing

Documents are chunked with financial-aware boundaries (preserving tables, lists, etc.)python main.py



### 2. Tree Building## ğŸ”§ Configuration```

RAPTOR recursively:

1. Embeds all chunks

2. Clusters similar chunks using GMM

3. Summarizes each clusterConfigure via `.env` file or environment variables:This will:

4. Repeats for multiple levels

1. Load the included PDF document

### 3. Retrieval

When querying:```bash2. Build a RAPTOR tree structure

1. Query is embedded

2. Most relevant nodes are found# Required3. Run example queries

3. Context is gathered from nodes and children

OPENAI_API_KEY=sk-...4. Save and reload the system

### 4. Answer Generation

Retrieved context is fed to GPT-4 for accurate answers



## ğŸ“Š Comparison with Standard RAG# Recommended## Detailed Usage



| Feature | Standard RAG | FinRAG (RAPTOR) |LLAMA_CLOUD_API_KEY=llx-...

|---------|-------------|-----------------|

| Document Representation | Flat chunks | Hierarchical tree |### Configuration

| Retrieval | Single-level | Multi-level |

| Context | Fixed chunks | Adaptive summaries |# Optional customization

| Long Documents | May miss context | Better handling |

| Complex Queries | Limited | Improved performance |FINRAG_CHUNK_SIZE=512Customize FinRAG behavior through `FinRAGConfig`:



## ğŸ› ï¸ DevelopmentFINRAG_TOP_K=10



### Adding New FeaturesFINRAG_TREE_DEPTH=3```python



1. Add core logic to `src/finrag/core/`FINRAG_SUMMARIZATION_MODEL=gpt-3.5-turboconfig = FinRAGConfig(

2. Add model implementations to `src/finrag/models/`

3. Add utilities to `src/finrag/utils/````    # API Configuration

4. Update `__init__.py` files

5. Add examples to `examples/`    openai_api_key="your-key",

6. Update documentation in `docs/`

See [docs/ENV_SETUP.md](docs/ENV_SETUP.md) for all available options.    

## ğŸ¤ Contributing

    # Model Selection

Contributions welcome! Please:

## ğŸ§ª Testing    embedding_model="text-embedding-3-small",

1. Fork the repository

2. Create a feature branch    llm_model="gpt-4-turbo-preview",

3. Make your changes

4. Add tests if applicable```powershell    summarization_model="gpt-4-turbo-preview",

5. Update documentation

6. Submit a pull request# Test installation    



## ğŸ“ Referencespython tests/test_installation.py    # Chunking Parameters



- **RAPTOR Paper**: [Recursive Abstractive Processing for Tree-Organized Retrieval](https://arxiv.org/abs/2401.18059)    chunk_size=512,           # Tokens per chunk

- **RAPTOR GitHub**: [parthsarthi03/raptor](https://github.com/parthsarthi03/raptor)

# Test API keys    chunk_overlap=50,         # Overlap between chunks

## ğŸ“„ License

python tests/test_openai_key.py    

MIT License - See LICENSE file for details

```    # Tree Parameters

## ğŸ“ Support

    tree_depth=3,             # Maximum tree depth

- **Documentation**: See `docs/` folder

- **Issues**: Report on GitHub## ğŸ“¦ Package Installation    max_cluster_size=100,     # Maximum nodes per cluster

- **Questions**: Check `docs/QUICKREF.md`

    min_cluster_size=5,       # Minimum nodes per cluster

## ğŸ™ Acknowledgments

Install as a package for use in other projects:    

- Based on [RAPTOR](https://github.com/parthsarthi03/raptor) architecture

- Uses OpenAI API for embeddings and language models    # Retrieval Parameters

- LlamaParse for advanced PDF parsing

```powershell    top_k=10,                 # Number of documents to retrieve

---

# Development mode (editable)    similarity_threshold=0.7, # Minimum similarity score

**Happy Financial Analysis! ğŸš€ğŸ“Š**

pip install -e .    traversal_method="tree_traversal"  # or "collapsed_tree"

)

# Production mode```

pip install .

```### Loading Documents



Then import anywhere:**From PDF:**

```python

```pythontext = finrag.load_pdf("report.pdf")

from finrag import FinRAG, FinRAGConfigfinrag.add_documents([text])

``````



## ğŸ”‘ Features**From Text File:**

```python

- âœ… **Hierarchical RAG** - Multi-level document representation with RAPTORtext = finrag.load_text("document.txt")

- âœ… **Financial Focus** - Optimized for financial documents and analysisfinrag.add_documents([text])

- âœ… **LlamaParse Integration** - Advanced PDF parsing with table preservation```

- âœ… **Flexible Configuration** - Easy customization via .env or code

- âœ… **Multiple Retrieval Strategies** - Tree traversal and collapsed tree search**Multiple Documents:**

- âœ… **Caching** - Save and load processed indices```python

- âœ… **Progress Indicators** - Real-time feedback during processingdocs = [

- âœ… **Production Ready** - Proper error handling and validation    finrag.load_pdf("q1_report.pdf"),

    finrag.load_pdf("q2_report.pdf"),

## ğŸ› ï¸ Development    finrag.load_text("analysis.txt")

]

### Project Structure Philosophyfinrag.add_documents(docs)

```

- **`src/finrag/`** - All source code organized by functionality

- **`examples/`** - Self-contained example scripts### Querying

- **`tests/`** - Testing and validation

- **`docs/`** - Comprehensive documentation**Basic Query:**

- **`scripts/`** - Setup and utility scripts```python

result = finrag.query("What are the key financial metrics?")

### Adding New Featuresprint(result['answer'])

```

1. Add core logic to `src/finrag/core/`

2. Add model implementations to `src/finrag/models/`**Custom Retrieval:**

3. Add utilities to `src/finrag/utils/````python

4. Update `__init__.py` files for exportsresult = finrag.query(

5. Add examples to `examples/`    question="What is the profit margin?",

6. Update documentation in `docs/`    retrieval_method="collapsed_tree",

    top_k=15

## ğŸ“„ License)

```

MIT License - See LICENSE file for details

**Access Retrieved Documents:**

## ğŸ¤ Contributing```python

result = finrag.query("What are the risk factors?")

Contributions welcome! Please:

print(f"Answer: {result['answer']}")

1. Fork the repositoryprint(f"\nRetrieved {len(result['retrieved_nodes'])} nodes:")

2. Create a feature branch

3. Make your changesfor i, node in enumerate(result['retrieved_nodes'][:5], 1):

4. Add tests if applicable    print(f"{i}. Level {node['level']} (Score: {node['score']:.3f})")

5. Update documentation    print(f"   {node['text_preview']}\n")

6. Submit a pull request```



## ğŸ“ Support### Saving and Loading



- **Documentation**: See `docs/` folder**Save the System:**

- **Issues**: Report on GitHub Issues```python

- **Questions**: Check `docs/QUICKREF.md` for quick answersfinrag.save("./my_finrag_index")

```

## ğŸ™ Acknowledgments

**Load a Saved System:**

- Based on [RAPTOR](https://github.com/parthsarthi03/raptor) architecture```python

- Uses OpenAI API for embeddings and language modelsfinrag_new = FinRAG(config)

- LlamaParse for advanced PDF parsingfinrag_new.load("./my_finrag_index")



---# Now you can query without rebuilding

result = finrag_new.query("Summary of financial performance")

**Happy Financial Analysis! ğŸš€ğŸ“Š**```


### Statistics

```python
stats = finrag.get_statistics()
print(f"Total nodes: {stats['total_nodes']}")
print(f"Tree depth: {stats['tree_depth']}")
print(f"Nodes per level: {stats['levels']}")
```

## Advanced Features

### Custom Models

FinRAG supports custom implementations for all components:

```python
from base_models import BaseEmbeddingModel, BaseSummarizationModel, BaseQAModel

class CustomEmbedding(BaseEmbeddingModel):
    def create_embedding(self, text):
        # Your embedding logic
        return embedding_vector

class CustomSummarizer(BaseSummarizationModel):
    def summarize(self, texts, max_tokens=200):
        # Your summarization logic
        return summary

class CustomQA(BaseQAModel):
    def answer_question(self, context, question):
        # Your QA logic
        return {"answer": answer}

# Use custom models
from tree import RAPTORTree, TreeConfig

tree = RAPTORTree(
    embedding_model=CustomEmbedding(),
    summarization_model=CustomSummarizer(),
    config=TreeConfig()
)
```

### Retrieval Methods

**Tree Traversal (Default):**
- Starts from high-level summaries
- Progressively drills down to details
- Better for broad questions

**Collapsed Tree:**
- Searches all levels simultaneously
- Better for specific, detailed queries

```python
# Tree traversal
result = finrag.query(
    "Give me an overview of the company's performance",
    retrieval_method="tree_traversal"
)

# Collapsed tree
result = finrag.query(
    "What was the exact revenue in Q3 2024?",
    retrieval_method="collapsed_tree"
)
```

## Performance Tips

1. **Chunk Size**: Smaller chunks (256-512) work better for precise queries; larger chunks (512-1024) for broader context

2. **Tree Depth**: 
   - Depth 2-3: Good for most documents
   - Depth 4+: Large document collections
   
3. **Top-K**: 
   - 5-10: Focused, specific answers
   - 15-20: Comprehensive answers with more context

4. **Caching**: Enable caching for repeated queries on the same documents

## Project Structure

```
FinRAG/
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ base_models.py         # Abstract base classes
â”œâ”€â”€ models.py              # OpenAI model implementations
â”œâ”€â”€ clustering.py          # RAPTOR clustering algorithm
â”œâ”€â”€ tree.py               # RAPTOR tree structure
â”œâ”€â”€ retrieval.py          # Retrieval strategies
â”œâ”€â”€ finrag.py             # Main FinRAG class
â”œâ”€â”€ utils.py              # Utility functions
â”œâ”€â”€ main.py               # Example usage
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md            # This file
```

## How It Works

### 1. Document Processing

Documents are chunked into manageable pieces with financial-aware boundaries (preserving tables, lists, etc.)

### 2. Tree Building

RAPTOR recursively:
1. Embeds all chunks
2. Clusters similar chunks using Gaussian Mixture Models
3. Summarizes each cluster
4. Repeats for multiple levels

### 3. Retrieval

When you query:
1. Query is embedded
2. Most relevant nodes are found (tree traversal or collapsed tree)
3. Context is gathered from retrieved nodes and their children

### 4. Answer Generation

Retrieved context is fed to GPT-4 to generate accurate, grounded answers

## Comparison with Standard RAG

| Feature | Standard RAG | FinRAG (RAPTOR-based) |
|---------|-------------|----------------------|
| Document Representation | Flat chunks | Hierarchical tree |
| Retrieval | Single-level | Multi-level |
| Context | Fixed-size chunks | Adaptive (summaries + details) |
| Long Documents | May miss context | Better at handling long docs |
| Performance | Good for simple queries | Better for complex queries |

## References

- **RAPTOR Paper**: [Recursive Abstractive Processing for Tree-Organized Retrieval](https://arxiv.org/abs/2401.18059)
- **RAPTOR GitHub**: [parthsarthi03/raptor](https://github.com/parthsarthi03/raptor)

## License

MIT License

## Contributing

Contributions welcome! Areas for improvement:
- Support for more embedding models (e.g., Cohere, Voyage)
- Custom financial entity extraction
- Table and chart processing
- Multi-modal document support
- Query optimization

## Troubleshooting

**Issue: Out of memory during tree building**
- Reduce `chunk_size` or `max_cluster_size`
- Process documents in batches

**Issue: Slow retrieval**
- Reduce `top_k`
- Use `collapsed_tree` method
- Enable caching

**Issue: Poor answer quality**
- Increase `top_k` for more context
- Try different `retrieval_method`
- Adjust `chunk_size` and `chunk_overlap`

## Support

For issues and questions, please refer to:
- Original RAPTOR repository: https://github.com/parthsarthi03/raptor
- OpenAI Documentation: https://platform.openai.com/docs
