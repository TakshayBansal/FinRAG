
---

# FinRAG â€” Financial Retrieval-Augmented Generation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenAI](https://img.shields.io/badge/OpenAI-Optional-green.svg)](https://openai.com/)
[![Free Models](https://img.shields.io/badge/Free%20Models-Available-brightgreen.svg)](https://huggingface.co/)

FinRAG is a **domain-aware RAG system** for financial documents, built on the **RAPTOR** (Recursive Abstractive Processing for Tree-Organized Retrieval) architecture. It adds financial-specific parsing, chunking, and retrieval strategies for accurate, grounded Q&A over long, complex reports.

ğŸ†• **Now works WITHOUT OpenAI API key** using free open-source AI models!

---

## ğŸŒŸ Key Features

### Core Features
* ğŸŒ³ **Hierarchical RAG (RAPTOR):** Multi-level representations (chunks â†’ year groups â†’ company summaries â†’ sector summaries â†’ global).
* ğŸ“Š **Financial Context Awareness:** Metadata clustering by sector, company, and year.
* ğŸ§¾ **Advanced PDF Parsing:** Filtered parsing with LlamaParse integration and PyPDF2 fallback.
* ğŸ” **Multiple Retrieval Strategies:** Tree traversal (hierarchical) and collapsed-tree (flat) search.
* ğŸ¯ **Semantic Search:** High-quality embeddings (OpenAI or sentence-transformers).
* ğŸ’¾ **Pre-built Tree System:** Build once from all PDFs, load instantly (30x faster).

### ğŸ†• New Features
* âœ¨ **FREE AI Models:** Works without OpenAI API key using FLAN-T5 and sentence-transformers
* ğŸ¨ **Rich Formatting:** Beautiful terminal output with colors, tables, and progress bars
* ğŸ“ˆ **Stock Scoring System:** Ensemble scoring with 5 methods (sentiment, trends, risk, quantitative, LLM)
* ğŸ”„ **Automatic Fallback:** Gracefully switches between OpenAI and free models
* âš¡ **Lazy Loading:** Fast startup with models loaded on first use
* ğŸ¯ **Metadata Clustering:** Hierarchical organization by financial metadata

---

## ğŸ“ Project Structure

```
FinRAG/
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ examples/             # Ready-to-run examples
â”œâ”€â”€ scripts/              # Utilities
â”œâ”€â”€ tests/                # Test scripts
â”œâ”€â”€ src/finrag/
â”‚   â”œâ”€â”€ core/             # Core algorithms (clustering, tree, retrieval)
â”‚   â”œâ”€â”€ models/           # Model wrappers (OpenAI, etc.)
â”‚   â””â”€â”€ utils/            # Env loader, helpers
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md
```

*For a deeper breakdown, see `docs/PROJECT_STRUCTURE.md` (optional).*

---

## ğŸš€ Quick Start

### 1) Install

```bash
# Clone and install dependencies
git clone <your-repo-url>
cd FinRAG
pip install -r requirements.txt
```

### 2) Configure API Keys (Optional!)

FinRAG now works **without OpenAI API key** using free models!

#### Option A: Use FREE Models (No API Key Needed)
```python
from finrag import FinRAG

# Works immediately with free AI models!
finrag = FinRAG()  # âœ… No API key required
```

#### Option B: Use OpenAI (Better Quality)
```bash
# Windows PowerShell
$env:OPENAI_API_KEY="sk-your-key-here"

# Linux/Mac
export OPENAI_API_KEY="sk-your-key-here"
```

Or create a `.env` file:
```bash
# .env
OPENAI_API_KEY=sk-your-key-here

# Optional (better PDF parsing)
LLAMA_CLOUD_API_KEY=llx-your-key-here
```

### 3) Build Pre-Built Tree (Once)

```bash
# Build tree from all PDFs in data/ folder
python scripts/build_tree.py

# This creates finrag_tree/ directory
# Only needs to be done once!
```

### 4) Run Examples

```bash
# Test fallback models (no API key needed)
python examples/test_fallback.py

# Interactive tree management
python scripts/manage_tree.py stats
python scripts/manage_tree.py query "Your question"

# Stock scoring example (requires API key)
python examples/stock_scoring_example.py

# Simple examples
python examples/example.py
python examples/main.py
```

---

## ğŸ’» Usage

### ğŸ†• Using Pre-Built Tree (Recommended)

```python
from finrag import FinRAG

# Load pre-built tree (instant! no rebuilding)
finrag = FinRAG()
finrag.tree.load("finrag_tree")

# Query the tree
result = finrag.query("What is the revenue trend?")
print(result["answer"])

# Show statistics
stats = finrag.get_statistics()
print(f"Total nodes: {stats['total_nodes']}")
print(f"Tree depth: {stats['tree_depth']}")
```

### Basic Usage (Build from Scratch)

```python
from finrag import FinRAG, FinRAGConfig

# Initialize (uses free models if no API key)
finrag = FinRAG()

# Add documents with metadata
documents = [
    {
        "text": "Apple Inc. reported revenue of $100B...",
        "metadata": {
            "sector": "Technology",
            "company": "Apple Inc.",
            "year": "2024"
        }
    }
]

# Build tree
finrag.build_tree(documents)

# Save for later use
finrag.tree.save("finrag_tree")

# Query
result = finrag.query("What is Apple's revenue?")
print(result["answer"])
```

### PDF Processing

```python
from finrag import FinRAG
from finrag.utils.filtered_parser import FilteredDocumentParser

# Initialize parser
parser = FilteredDocumentParser()

# Parse PDF with filtering
result = parser.parse_with_filtering(
    pdf_path="financial_report.pdf",
    company_name="Apple Inc.",
    year=2024,
    sector="Technology"
)

# Build tree from parsed documents
finrag = FinRAG()
finrag.build_tree(result["documents"])
```

### ğŸ¨ Rich Formatted Output

```python
from finrag import FinRAG
from rich.console import Console

console = Console()
finrag = FinRAG()
finrag.tree.load("finrag_tree")

# Query with beautiful output
result = finrag.query("What are the key financial metrics?")

# Display with Rich formatting
from rich.panel import Panel
console.print(Panel(result["answer"], title="Answer", border_style="green"))
```

### ğŸ“ˆ Stock Scoring

```python
from finrag import FinRAG
from finrag.scoring import EnsembleScorer

# Load pre-built tree
finrag = FinRAG()
finrag.tree.load("finrag_tree")

# Initialize scorer
scorer = EnsembleScorer()

# Score a company
result = scorer.score_company(
    finrag=finrag,
    ticker="AAPL",
    company_name="Apple Inc.",
    ticker_suffix=".US"
)

print(f"Score: {result.score}/100")
print(f"Direction: {result.direction}")
print(f"Confidence: {result.confidence}%")
```

### Custom Configuration

```python
from finrag import FinRAG, FinRAGConfig

config = FinRAGConfig(
    chunk_size=512,
    top_k=10,
    tree_depth=4,
    use_metadata_clustering=True,
    embedding_model="text-embedding-3-small",
    summarization_model="gpt-3.5-turbo",
    llm_model="gpt-4-turbo-preview"
)
finrag = FinRAG(config)
```

### Tree Management CLI

```bash
# Build tree from all PDFs
python scripts/manage_tree.py build

# View statistics with beautiful tables
python scripts/manage_tree.py stats

# Query with formatted output
python scripts/manage_tree.py query "What is the revenue trend?"
```

### Access retrieved context

```python
res = finrag.query("What are the risk factors?")
print("Answer:", res["answer"])
print("Retrieved nodes:", len(res["retrieved_nodes"]))
for n in res["retrieved_nodes"][:5]:
    print(f"- Level {n['level']}  Score {n['score']:.3f}")
```

---

## ğŸ—ï¸ Architecture

### RAPTOR Tree with Metadata Clustering

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Financial Documents (PDFs)                     â”‚
â”‚  â†’ Filtered parsing extracts financial info                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  (LlamaParse or PyPDF2)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Financial-Aware Chunking                    â”‚
â”‚  â†’ Respects tables, financial statements                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  (OpenAI or sentence-transformers)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Embedding Generation                       â”‚
â”‚  â†’ 1536D (OpenAI) or 384D (sentence-transformers)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  (Metadata clustering)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hierarchical RAPTOR Tree                       â”‚
â”‚  Level 4: Global Summary (All Sectors)                     â”‚
â”‚  Level 3: Sector Summaries (e.g., Technology)              â”‚
â”‚  Level 2: Company Summaries (e.g., Apple Inc.)             â”‚
â”‚  Level 1: Year Groups (e.g., 2024 reports)                 â”‚
â”‚  Level 0: Original Chunks (512 tokens each)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  (Tree traversal or collapsed search)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Query Processing & Retrieval                     â”‚
â”‚  â†’ Semantic similarity search across tree levels           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  (GPT-4 or FLAN-T5 with context)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Question Answering                           â”‚
â”‚  â†’ Grounded answers with citations                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ†• Automatic Model Fallback

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FinRAG Initialization              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Check API Key â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
  âœ… Valid         âŒ Missing/Invalid
        â”‚                 â”‚
        â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Modelsâ”‚  â”‚ FREE AI Models   â”‚
â”‚              â”‚  â”‚                  â”‚
â”‚ â€¢ GPT-4      â”‚  â”‚ â€¢ FLAN-T5-small  â”‚
â”‚ â€¢ GPT-3.5    â”‚  â”‚ â€¢ sentence-trans â”‚
â”‚ â€¢ Embeddings â”‚  â”‚ â€¢ 80M parameters â”‚
â”‚              â”‚  â”‚                  â”‚
â”‚ Quality:100% â”‚  â”‚ Quality: 60-70%  â”‚
â”‚ Cost: $$$    â”‚  â”‚ Cost: FREE âœ¨    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Configuration

### Environment Variables

```bash
# OpenAI API Key (OPTIONAL - works without it!)
OPENAI_API_KEY=sk-...

# LlamaParse for better PDF parsing (optional)
LLAMA_CLOUD_API_KEY=llx-...

# Model Selection
FINRAG_EMBEDDING_MODEL=text-embedding-3-small
FINRAG_SUMMARIZATION_MODEL=gpt-3.5-turbo
FINRAG_LLM_MODEL=gpt-4-turbo-preview

# Tree Configuration
FINRAG_CHUNK_SIZE=512
FINRAG_CHUNK_OVERLAP=50
FINRAG_TREE_DEPTH=4
FINRAG_USE_METADATA_CLUSTERING=true

# Retrieval Settings
FINRAG_TOP_K=10
FINRAG_SIMILARITY_THRESHOLD=0.7
FINRAG_TRAVERSAL_METHOD=tree_traversal

# Clustering Parameters
FINRAG_MAX_CLUSTER_SIZE=100
FINRAG_MIN_CLUSTER_SIZE=5
FINRAG_SUMMARIZATION_LENGTH=200
```

### Python Configuration

```python
from finrag import FinRAGConfig

# Use defaults (works without API key!)
config = FinRAGConfig()

# Custom configuration
config = FinRAGConfig(
    # Optional: API keys
    openai_api_key="sk-...",
    llamaparse_api_key="llx-...",
    
    # Model selection
    embedding_model="text-embedding-3-small",
    summarization_model="gpt-3.5-turbo",
    llm_model="gpt-4-turbo-preview",
    
    # Tree parameters
    chunk_size=512,
    chunk_overlap=50,
    tree_depth=4,
    use_metadata_clustering=True,
    
    # Retrieval
    top_k=10,
    similarity_threshold=0.7
)

finrag = FinRAG(config)
```

### Model Selection Guide

| Use Case | Embedding | Summarization | QA | Cost |
|----------|-----------|---------------|-----|------|
| **Free (No API)** | sentence-transformers | FLAN-T5-small | FLAN-T5-small | FREE âœ¨ |
| **Balanced** | OpenAI | GPT-3.5-turbo | GPT-3.5-turbo | $ |
| **Best Quality** | OpenAI | GPT-4-turbo | GPT-4-turbo | $$$ |
| **Production** | OpenAI | GPT-3.5-turbo | GPT-4-turbo | $$ |

---

## ğŸ” Retrieval Methods

### Tree Traversal (Hierarchical)
Best for: Broad questions, overviews, comparisons

```python
result = finrag.query(
    "Give me an overview of the technology sector performance",
    retrieval_method="tree_traversal",
    top_k=10
)
```

**How it works:**
- Starts at root node
- Greedy descent through tree levels
- Returns nodes from multiple levels
- Good for understanding context

### Collapsed Tree (Flat Search)
Best for: Specific facts, precise numbers, dates

```python
result = finrag.query(
    "What was Apple's exact revenue in Q3 2024?",
    retrieval_method="collapsed_tree",
    top_k=10
)
```

**How it works:**
- Flattens all nodes to single list
- Ranks by similarity with layer weighting
- Returns most relevant chunks
- Good for factual accuracy

### When to Use Each

| Question Type | Method | Why |
|---------------|--------|-----|
| "What is the overall trend...?" | tree_traversal | Needs context from multiple levels |
| "Compare companies..." | tree_traversal | Hierarchical comparison |
| "What was the revenue...?" | collapsed_tree | Specific fact |
| "Give me an overview..." | tree_traversal | Broad understanding |
| "What date did...?" | collapsed_tree | Precise detail |

---

## ğŸ“Š Advanced Features

### Stock Scoring System

FinRAG includes a sophisticated **ensemble scoring system** for stock prediction:

```python
from finrag import FinRAG
from finrag.scoring import EnsembleScorer

finrag = FinRAG()
finrag.tree.load("finrag_tree")

scorer = EnsembleScorer()
result = scorer.score_company(
    finrag=finrag,
    ticker="AAPL",
    company_name="Apple Inc."
)

print(f"Score: {result.score}/100")
print(f"Direction: {result.direction}")  # bullish/bearish/neutral
print(f"Confidence: {result.confidence}%")
print(f"Time Horizon: {result.time_horizon}")
```

**Scoring Methods (Weighted Ensemble):**
1. **Sentiment Analysis** (25%): Multi-aspect sentiment from annual reports
2. **YoY Trends** (20%): Revenue and earnings growth analysis
3. **Risk-Adjusted** (20%): Risk factors and uncertainties
4. **Quantitative Metrics** (20%): 40+ financial metrics from yfinance
5. **LLM Judge** (15%): GPT-4 holistic assessment

**Output:**
- Score: 0-100 (investment attractiveness)
- Direction: bullish/bearish/neutral
- Confidence: Ensemble agreement score
- Detailed breakdown of all components
- Financial metrics (P/E, ROE, margins, etc.)

See `examples/stock_scoring_example.py` for full demo with Rich formatting!

### Tree Statistics & Visualization

```python
# Get detailed statistics
stats = finrag.get_statistics()
print(f"Total nodes: {stats['total_nodes']}")
print(f"Tree depth: {stats['tree_depth']}")
print(f"Nodes per level: {stats['levels']}")

# Access tree structure
for level, nodes in finrag.tree.layers.items():
    print(f"Level {level}: {len(nodes)} nodes")
    
# Get metadata distribution
if finrag.tree.use_metadata_clustering:
    print("Sectors:", finrag.tree.get_sectors())
    print("Companies:", finrag.tree.get_companies())
    print("Years:", finrag.tree.get_years())
```

### Pre-Built Tree Management

```bash
# Build tree from all PDFs (one-time)
python scripts/build_tree.py

# View statistics with Rich tables
python scripts/manage_tree.py stats

# Query with beautiful formatting
python scripts/manage_tree.py query "Your question"

# Build and save
python scripts/manage_tree.py build
```

**Benefits:**
- Build once, use many times
- 30x faster loading (10s vs 5min)
- Consistent across examples
- Easy to share and version

---

## ğŸ§ª Testing

### Installation Tests

```bash
# Test dependencies
python tests/test_installation.py

# Test OpenAI API key (if using)
python tests/test_openai_key.py

# Test fallback models (no API key)
python examples/test_fallback.py
```

### Example Tests

```bash
# Test tree building and querying
python examples/example.py

# Test metadata clustering
python examples/metadata_clustering_example.py

# Test filtered parsing
python examples/filtered_parsing_example.py

# Test stock scoring (requires API key)
python examples/stock_scoring_example.py

# Test tree management
python scripts/manage_tree.py stats
```

---

## ğŸ“¦ Using as a Package

```bash
# development
pip install -e .

# production
pip install .
```

Then:

```python
from finrag import FinRAG, FinRAGConfig
```

---

## ğŸ§° Advanced (Custom Models)

```python
from base_models import BaseEmbeddingModel, BaseSummarizationModel, BaseQAModel
from tree import RAPTORTree, TreeConfig

class CustomEmbedding(BaseEmbeddingModel):
    def create_embedding(self, text): ...
class CustomSummarizer(BaseSummarizationModel):
    def summarize(self, texts, max_tokens=200): ...
class CustomQA(BaseQAModel):
    def answer_question(self, context, question): ...

tree = RAPTORTree(
    embedding_model=CustomEmbedding(),
    summarization_model=CustomSummarizer(),
    config=TreeConfig()
)
```

---

## âš™ï¸ Performance Tips

### Tree Building
1. **Pre-build once:** Use `scripts/build_tree.py` to build from all PDFs once
2. **Load instantly:** `finrag.tree.load("finrag_tree")` is 30x faster than rebuilding
3. **Chunk size:** 512 tokens is optimal for financial documents
4. **Metadata clustering:** Enable for better hierarchical organization

### Querying
1. **Choose right method:** 
   - `tree_traversal` for broad questions
   - `collapsed_tree` for specific facts
2. **Adjust top_k:**
   - 5-10 for focused answers
   - 15-20 for comprehensive context
3. **Use caching:** Tree only needs to be built once

### Model Selection
1. **Free models (no API):**
   - Fast initialization with lazy loading
   - Good for development and testing
   - ~60-70% quality of OpenAI
2. **OpenAI models:**
   - Best quality for production
   - Required for stock scoring
   - Higher API costs

### Optimization
| Operation | Slow Method | Fast Method | Speedup |
|-----------|-------------|-------------|---------|
| Tree Building | Build every time | Pre-build once | 30x |
| Loading | From PDFs | From finrag_tree/ | 30x |
| Embeddings | OpenAI API | sentence-transformers | 2-4x |
| Queries | Large top_k | Optimized top_k | 2x |

---

## ğŸ§¯ Troubleshooting

### Common Issues

**No OpenAI API Key**
```
âœ… This is fine! FinRAG works without it using free models.
âœ… Shows: "Using FREE open-source AI models"
âš ï¸ Quality: ~60-70% of OpenAI
ğŸ’¡ For best results: Set OPENAI_API_KEY environment variable
```

**Import Errors**
```bash
# Missing transformers
pip install transformers torch

# Missing sentence-transformers
pip install sentence-transformers

# Missing rich
pip install rich

# Install all dependencies
pip install -r requirements.txt
```

**Tree Building Issues**
```python
# Out of memory
# Solution: Lower max_cluster_size
config = FinRAGConfig(max_cluster_size=50)

# Slow building
# Solution: Use pre-built tree system
python scripts/build_tree.py  # Build once
finrag.tree.load("finrag_tree")  # Load instantly
```

**Retrieval Issues**
```python
# Weak answers
# Solution 1: Increase top_k
result = finrag.query("...", top_k=15)

# Solution 2: Try different retrieval method
result = finrag.query("...", retrieval_method="collapsed_tree")

# Solution 3: Check tree has relevant documents
stats = finrag.get_statistics()
print(stats)
```

**PDF Parsing Issues**
```python
# Tables not preserved
# Solution: Use LlamaParse
config = FinRAGConfig(llamaparse_api_key="llx-...")

# Or use filtered parser
from finrag.utils.filtered_parser import FilteredDocumentParser
parser = FilteredDocumentParser(use_llamaparse=True)
```

**Model Loading Slow**
```
âœ… This is normal on first use (models download)
âœ… Subsequent runs are fast (models cached)
ğŸ’¡ FLAN-T5-small: ~300MB download
ğŸ’¡ sentence-transformers: ~90MB download
```

### Error Messages

| Error | Cause | Solution |
|-------|-------|----------|
| `ValueError: OpenAI API key must be provided` | Old config validation | Update to latest code (validation removed) |
| `ImportError: sentence_transformers` | Missing dependency | `pip install sentence-transformers` |
| `ImportError: transformers` | Missing dependency | `pip install transformers torch` |
| `KeyError: 'score'` | Old code referencing wrong key | Use `result.sentiment_score` not `breakdown["sentiment_analysis"]["score"]` |
| `FileNotFoundError: finrag_tree` | Tree not built | Run `python scripts/build_tree.py` first |

---

## ğŸ“š Documentation

### Core Documentation
- **FALLBACK_GUIDE.md**: Complete guide to free models and fallback system
- **FLAN_T5_IMPLEMENTATION.md**: FLAN-T5 implementation details
- **TREE_MANAGEMENT_GUIDE.md**: Pre-built tree system guide
- **QUICKSTART_TREE.md**: 3-step quick start for tree system

### API References
- **RAPTOR paper**: [https://arxiv.org/abs/2401.18059](https://arxiv.org/abs/2401.18059)
- **RAPTOR GitHub**: [https://github.com/parthsarthi03/raptor](https://github.com/parthsarthi03/raptor)
- **OpenAI API**: [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **Hugging Face FLAN-T5**: [https://huggingface.co/google/flan-t5-small](https://huggingface.co/google/flan-t5-small)
- **sentence-transformers**: [https://www.sbert.net/](https://www.sbert.net/)

## ğŸ†• What's New

### Latest Features
- âœ¨ **FREE AI Models**: Works without OpenAI API key using FLAN-T5 and sentence-transformers
- ğŸ¨ **Rich Formatting**: Beautiful terminal output with colors, tables, progress bars
- ğŸ“ˆ **Stock Scoring**: Ensemble scoring with 5 methods (sentiment, trends, risk, quantitative, LLM)
- ğŸ”„ **Automatic Fallback**: Seamless switching between OpenAI and free models
- âš¡ **Pre-Built Trees**: Build once, load 30x faster
- ğŸ¯ **Metadata Clustering**: Hierarchical organization by sector/company/year
- ğŸ’¾ **Dual Save Format**: Pickle (fast) + JSON (always works) for tree persistence

### Model Quality Comparison

| Component | OpenAI | FLAN-T5 Free | Quality Ratio |
|-----------|--------|--------------|---------------|
| Embeddings | text-embedding-3-small (1536D) | sentence-transformers (384D) | 80% |
| Summarization | GPT-3.5-turbo | FLAN-T5-small | 60-70% |
| Question Answering | GPT-4 | FLAN-T5-small | 60-70% |
| **Cost** | $$$ per call | **FREE** âœ¨ | âˆ savings |
| **Speed** | ~1-3s (API) | ~1-3s (local) | Same |

### Performance Improvements

| Operation | Before | After | Improvement |
|-----------|--------|-------|-------------|
| Tree Loading | ~5 min (rebuild) | ~10 sec (load) | **30x faster** |
| First Query | ~5 min (build+query) | ~10 sec (load+query) | **30x faster** |
| Embeddings (free) | N/A | ~50ms | **New feature** |
| No API Key | âŒ Error | âœ… Works! | **Now possible** |

---

## ï¿½ Getting Started Checklist

- [ ] Clone repository: `git clone <repo-url>`
- [ ] Install dependencies: `pip install -r requirements.txt`
- [ ] **(Optional)** Set OpenAI API key: `$env:OPENAI_API_KEY="sk-..."`
- [ ] Test without API key: `python examples/test_fallback.py`
- [ ] Place PDFs in `data/` folder
- [ ] Build pre-built tree: `python scripts/build_tree.py`
- [ ] View statistics: `python scripts/manage_tree.py stats`
- [ ] Query tree: `python scripts/manage_tree.py query "Your question"`
- [ ] **(With API key)** Try stock scoring: `python examples/stock_scoring_example.py`

## ğŸ’¡ Quick Tips

1. **Start Free**: No API key needed! Works with free FLAN-T5 models
2. **Build Once**: Use `scripts/build_tree.py` to build from all PDFs once
3. **Load Fast**: Tree loads in 10 seconds vs 5 minutes rebuilding
4. **Rich Output**: Use `scripts/manage_tree.py` for beautiful formatted output
5. **Stock Scoring**: Requires OpenAI API key for best results
6. **Metadata Matters**: Add sector/company/year to documents for better organization

## ï¿½ğŸ“„ License

MIT â€” see `LICENSE`.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Implement your feature & add tests
4. Update documentation
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

---

## ğŸ™ Acknowledgments

- **RAPTOR**: Original architecture from [Stanford NLP](https://github.com/parthsarthi03/raptor)
- **OpenAI**: GPT models and embeddings API
- **Google**: FLAN-T5 open-source models
- **Hugging Face**: Transformers library and model hub
- **sentence-transformers**: High-quality free embeddings

---

## ğŸ“ Support

- ğŸ“– **Documentation**: See `.md` files in repository
- ğŸ› **Issues**: Open an issue on GitHub
- ğŸ’¬ **Discussions**: GitHub Discussions
- ğŸ“§ **Contact**: [Your contact info]

---

**Built with â¤ï¸ for the financial AI community**

---
